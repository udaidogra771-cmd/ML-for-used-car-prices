{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 6: Train/Test Split and Putting It Together\n",
    "\n",
    "Last session we learned to encode text into numbers with one-hot encoding.\n",
    "\n",
    "Now our data is ALL numbers. Almost ready for Machine Learning!\n",
    "\n",
    "But first, we need to answer: **How do we know if the AI actually learned, or just memorized?**\n",
    "\n",
    "Today we'll learn:\n",
    "- **Why** we split data into training and testing sets\n",
    "- **How** to split with `train_test_split()`\n",
    "- The **complete pipeline** from raw data to ML-ready data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. The Studying Analogy\n",
    "\n",
    "Imagine you're studying for a math test:\n",
    "\n",
    "- **Option A:** You practice 100 problems, then the test uses **the same 100 problems**.\n",
    "  - You got 100%. But did you actually learn math? Or just memorize answers?\n",
    "\n",
    "- **Option B:** You practice 80 problems, then the test has **20 NEW problems** you've never seen.\n",
    "  - If you score well on problems you've never seen, you actually **learned**.\n",
    "\n",
    "Machine Learning works the same way:\n",
    "\n",
    "- **Training set** (80%) = the practice problems. The AI studies these.\n",
    "- **Test set** (20%) = the final exam. We hide these and check later.\n",
    "\n",
    "If the AI predicts well on cars it has **never seen before**, it actually learned the patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. X and y: Features vs Target\n",
    "\n",
    "Before splitting, we need to separate our data into two parts:\n",
    "\n",
    "- **X** = the **features** (the information the AI uses to predict). Think: \"the questions on the exam.\"\n",
    "- **y** = the **target** (the value the AI tries to predict). Think: \"the answers.\"\n",
    "\n",
    "For our car project:\n",
    "- X = year, mileage, brand columns (what we know about the car)\n",
    "- y = price (what we want to predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Start with our encoded dataset (from Session 5)\n",
    "data = {\n",
    "    \"brand\":   [\"Ford\", \"Toyota\", \"BMW\", \"Ford\", \"Toyota\", \"Tesla\", \"BMW\", \"Ford\", \"BMW\", \"Ford\"],\n",
    "    \"year\":    [2018, 2015, 2019, 2012, 2020, 2022, 2017, 2016, 2021, 2003],\n",
    "    \"mileage\": [45000, 80000, 30000, 120000, 15000, 5000, 55000, 70000, 25000, 152000],\n",
    "    \"price\":   [18000, 12000, 35000, 5000, 25000, 55000, 22000, 13000, 42000, 8000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode brand (same as Session 5)\n",
    "df_encoded = pd.get_dummies(df, columns=[\"brand\"])\n",
    "\n",
    "print(\"--- Encoded data ---\")\n",
    "print(df_encoded)\n",
    "print()\n",
    "print(\"Columns:\", list(df_encoded.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df_encoded.drop(\"price\", axis=1)  # Everything EXCEPT price\n",
    "y = df_encoded[\"price\"]                # ONLY price\n",
    "\n",
    "print(\"--- X (Features: what the AI looks at) ---\")\n",
    "print(X)\n",
    "print()\n",
    "print(\"--- y (Target: what the AI predicts) ---\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shapes\n",
    "print(f\"X shape: {X.shape} — {X.shape[0]} cars, {X.shape[1]} features each\")\n",
    "print(f\"y shape: {y.shape} — {y.shape[0]} prices to predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. train_test_split: Dividing the Data\n",
    "\n",
    "Now we split X and y into:\n",
    "- `X_train`, `y_train` — for the AI to study\n",
    "- `X_test`, `y_test` — for the final exam\n",
    "\n",
    "We use sklearn's `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,      # 20% goes to the test set\n",
    "    random_state=42     # The \"shuffle seed\" — makes the split reproducible\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} cars (the AI studies these)\")\n",
    "print(f\"Test set:     {len(X_test)} cars (the final exam)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the arguments\n",
    "\n",
    "| Argument | What it does | Example |\n",
    "|----------|-------------|--------|\n",
    "| `X, y` | The data to split | Our features and prices |\n",
    "| `test_size=0.2` | How much to save for testing | 0.2 = 20%, 0.3 = 30% |\n",
    "| `random_state=42` | The shuffle seed | Same number = same split every time |\n",
    "\n",
    "The function returns **4 things** (in this exact order):\n",
    "1. `X_train` — training features\n",
    "2. `X_test` — test features\n",
    "3. `y_train` — training prices\n",
    "4. `y_test` — test prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at what the AI gets to study\n",
    "print(\"--- Training features (X_train) ---\")\n",
    "print(X_train)\n",
    "print()\n",
    "print(\"--- Training prices (y_train) ---\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the final exam — the AI has NEVER seen these\n",
    "print(\"--- Test features (X_test) ---\")\n",
    "print(X_test)\n",
    "print()\n",
    "print(\"--- Test prices (y_test) — the correct answers ---\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Experimenting with the Split\n",
    "\n",
    "Let's see how changing the arguments affects the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different test sizes\n",
    "for size in [0.1, 0.2, 0.3, 0.5]:\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=size, random_state=42)\n",
    "    pct = int(size * 100)\n",
    "    print(f\"test_size={size} → {len(X_tr)} train, {len(X_te)} test ({pct}% for testing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does random_state do?\n",
    "# Same random_state = same split every time\n",
    "_, X_test_a, _, _ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "_, X_test_b, _, _ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "_, X_test_c, _, _ = train_test_split(X, y, test_size=0.2, random_state=99)\n",
    "\n",
    "print(\"random_state=42 (first time), test rows:\", list(X_test_a.index))\n",
    "print(\"random_state=42 (second time), test rows:\", list(X_test_b.index))\n",
    "print(\"random_state=99, test rows:\", list(X_test_c.index))\n",
    "print()\n",
    "print(\"Same seed = same shuffle. Different seed = different shuffle.\")\n",
    "print(\"This way, your results are reproducible (anyone can get the same split).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. The Complete Pipeline (All Steps Together)\n",
    "\n",
    "Let's build the entire data preparation pipeline from scratch, step by step.\n",
    "\n",
    "This is what the n2 notebook does — and soon, you'll be able to build this from memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# THE COMPLETE ML DATA PIPELINE\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- STEP 1: Create or load the data ---\n",
    "data = {\n",
    "    \"brand\":   [\"Ford\", \"Toyota\", \"BMW\", \"Ford\", \"Toyota\", \"Tesla\", \"BMW\", \"Ford\", \"BMW\", \"Ford\"],\n",
    "    \"year\":    [2018, 2015, 2019, 2012, 2020, 2022, 2017, 2016, 2021, 2003],\n",
    "    \"mileage\": [45000, 80000, 30000, 120000, 15000, 5000, 55000, 70000, 25000, 152000],\n",
    "    \"price\":   [18000, 12000, 35000, 5000, 25000, 55000, 22000, 13000, 42000, 8000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"STEP 1 — Raw data:\")\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 2: Encode text columns ---\n",
    "df_encoded = pd.get_dummies(df, columns=[\"brand\"])\n",
    "print(\"STEP 2 — After encoding:\")\n",
    "print(df_encoded)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3: Separate features (X) and target (y) ---\n",
    "X = df_encoded.drop(\"price\", axis=1)\n",
    "y = df_encoded[\"price\"]\n",
    "print(\"STEP 3 — X and y:\")\n",
    "print(f\"  X shape: {X.shape} (features)\")\n",
    "print(f\"  y shape: {y.shape} (target)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 4: Split into train and test ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"STEP 4 — Train/Test Split:\")\n",
    "print(f\"  Training: {len(X_train)} cars\")\n",
    "print(f\"  Testing:  {len(X_test)} cars\")\n",
    "print()\n",
    "print(\"READY FOR MACHINE LEARNING!\")\n",
    "print(\"Next session: we give X_train and y_train to the AI, and it learns to predict prices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pipeline Summary\n",
    "\n",
    "```\n",
    "Raw data (dictionary/CSV)\n",
    "    ↓\n",
    "DataFrame\n",
    "    ↓\n",
    "Encode text → pd.get_dummies()\n",
    "    ↓\n",
    "Split X and y → df.drop() / df[\"column\"]\n",
    "    ↓\n",
    "Split train/test → train_test_split()\n",
    "    ↓\n",
    "Ready for ML!\n",
    "```\n",
    "\n",
    "Every ML project follows this pattern. The details change, but the steps are always the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Recap: What Each Variable Means\n",
    "\n",
    "After the pipeline, you have 6 key variables:\n",
    "\n",
    "| Variable | What it is | Shape in our example |\n",
    "|----------|-----------|---------------------|\n",
    "| `df` | The original raw data | 10 rows, 4 columns |\n",
    "| `df_encoded` | Data with text converted to numbers | 10 rows, 7 columns |\n",
    "| `X` | All features (everything except price) | 10 rows, 6 columns |\n",
    "| `y` | The target (prices) | 10 values |\n",
    "| `X_train` | Features the AI studies | 8 rows, 6 columns |\n",
    "| `X_test` | Features for the final exam | 2 rows, 6 columns |\n",
    "| `y_train` | Prices the AI studies | 8 values |\n",
    "| `y_test` | Correct prices for the final exam | 2 values |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# CHALLENGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Split and Explore\n",
    "\n",
    "Using the encoded data from Section 5 (already created above as `X` and `y`):\n",
    "\n",
    "1. Split with `test_size=0.3` (30% testing) and `random_state=7`\n",
    "2. Print how many cars are in the training set and test set\n",
    "3. Print the test set features (`X_test`) — which cars ended up in the test set?\n",
    "4. Print the test set prices (`y_test`) — what are their actual prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X and y already exist from Section 5\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Build the Pipeline from a New Dataset\n",
    "\n",
    "Build the complete pipeline from scratch using this data:\n",
    "\n",
    "```python\n",
    "phones = {\n",
    "    \"brand\":   [\"Apple\", \"Samsung\", \"Apple\", \"Google\", \"Samsung\", \"Apple\", \"Google\", \"Samsung\"],\n",
    "    \"storage\": [128, 256, 256, 128, 128, 512, 256, 512],\n",
    "    \"age\":     [1, 2, 1, 3, 2, 1, 1, 2],\n",
    "    \"price\":   [800, 600, 900, 350, 450, 1100, 500, 700]\n",
    "}\n",
    "```\n",
    "\n",
    "Steps:\n",
    "1. Create a DataFrame\n",
    "2. Encode the brand column with `pd.get_dummies()`\n",
    "3. Separate X (features) and y (price)\n",
    "4. Split into train/test with `test_size=0.25, random_state=42`\n",
    "5. Print the shape of each: `X_train`, `X_test`, `y_train`, `y_test`\n",
    "\n",
    "This is a completely different dataset — but the pipeline is identical!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "phones = {\n",
    "    \"brand\":   [\"Apple\", \"Samsung\", \"Apple\", \"Google\", \"Samsung\", \"Apple\", \"Google\", \"Samsung\"],\n",
    "    \"storage\": [128, 256, 256, 128, 128, 512, 256, 512],\n",
    "    \"age\":     [1, 2, 1, 3, 2, 1, 1, 2],\n",
    "    \"price\":   [800, 600, 900, 350, 450, 1100, 500, 700]\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Build from Memory\n",
    "\n",
    "This is the big one. **Without looking at the code above**, build the complete pipeline for this car data:\n",
    "\n",
    "```python\n",
    "cars = {\n",
    "    \"brand\":   [\"Honda\", \"Ford\", \"Toyota\", \"Honda\", \"Ford\", \"Tesla\"],\n",
    "    \"year\":    [2020, 2018, 2019, 2017, 2021, 2023],\n",
    "    \"mileage\": [30000, 55000, 42000, 78000, 12000, 3000],\n",
    "    \"price\":   [23000, 15000, 19000, 11000, 28000, 52000]\n",
    "}\n",
    "```\n",
    "\n",
    "From memory, do all 4 steps:\n",
    "1. DataFrame\n",
    "2. Encode\n",
    "3. X/y split\n",
    "4. Train/test split (80/20, random_state=42)\n",
    "\n",
    "Print the number of training and test cars at the end.\n",
    "\n",
    "If you get stuck, look back — but try at least 3 minutes on your own first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the COMPLETE pipeline from memory!\n",
    "\n",
    "cars = {\n",
    "    \"brand\":   [\"Honda\", \"Ford\", \"Toyota\", \"Honda\", \"Ford\", \"Tesla\"],\n",
    "    \"year\":    [2020, 2018, 2019, 2017, 2021, 2023],\n",
    "    \"mileage\": [30000, 55000, 42000, 78000, 12000, 3000],\n",
    "    \"price\":   [23000, 15000, 19000, 11000, 28000, 52000]\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: The test_size Experiment\n",
    "\n",
    "Using the car data from Challenge 3, try 5 different `test_size` values: `0.1, 0.2, 0.3, 0.4, 0.5`.\n",
    "\n",
    "For each one, print how many cars go to training and how many go to testing.\n",
    "\n",
    "Then answer as a comment:\n",
    "- What happens if `test_size` is too small (like 0.1)?\n",
    "- What happens if `test_size` is too large (like 0.5)?\n",
    "- Why is 0.2 (20%) a common choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Answers:\n",
    "# Too small test_size: \n",
    "# Too large test_size: \n",
    "# Why 0.2 is common: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5: Pipeline with Real Data\n",
    "\n",
    "Apply the pipeline to the real CSV dataset:\n",
    "\n",
    "1. Load `../data/usedcarprices_sujayr_train.csv`\n",
    "2. Select only these columns: `Year`, `Kilometers_Driven`, `Fuel_Type`, `Transmission`, `Price`\n",
    "   - Hint: `df = df[[\"Year\", \"Kilometers_Driven\", \"Fuel_Type\", \"Transmission\", \"Price\"]]`\n",
    "3. Drop rows with missing values: `df = df.dropna()`\n",
    "4. Encode `Fuel_Type` and `Transmission` with `pd.get_dummies()`\n",
    "5. Create X (drop Price) and y (just Price)\n",
    "6. Split into train/test (80/20, random_state=42)\n",
    "7. Print the shapes of X_train and X_test\n",
    "\n",
    "You just prepared a **real dataset** for Machine Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
